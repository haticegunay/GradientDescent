# GradientDescent

Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. In machine learning, we use gradient descent to update the parameters of our model. Parameters refer to coefficients in Linear Regression and weights in neural networks.
